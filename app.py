import streamlit as st
import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB

# --- 1. SAYFA VE STÄ°L AYARLARI ---
st.set_page_config(
    page_title="Duygu Analizi Projesi", 
    page_icon="ğŸ§ ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS TasarÄ±mÄ±
st.markdown("""
<style>
    .result-card {
        padding: 20px;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    }
    .main-title {
        text-align: center;
        color: #2E86C1;
        font-family: 'Helvetica', sans-serif;
    }
    .sub-title {
        text-align: center;
        color: #5D6D7E;
        font-size: 20px;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. YAN MENÃœ (DÃœZELTÄ°LDÄ°: ALT ALTA LÄ°STE) ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3069/3069172.png", width=100)
    st.title("Proje KÃ¼nyesi")
    st.info("**Ders:** Ã–rÃ¼ntÃ¼ TanÄ±ma")
    st.write("**Konu:** TÃ¼rkÃ§e Tweetlerde Duygu Analizi")
    st.write("---")
    
    st.markdown("### âš™ï¸ Teknoloji YÄ±ÄŸÄ±nÄ±")
    # BURAYI DÃœZELTTÄ°M: Alt alta maddeler halinde
    st.markdown("""
    * ğŸ **Python 3.11**
    * ğŸ¼ **Pandas** (Veri Ä°ÅŸleme)
    * ğŸ¤– **Scikit-Learn** (Yapay Zeka)
    * ğŸ¨ **Streamlit** (ArayÃ¼z)
    """)
    
    st.write("---")
    st.markdown("### ğŸ§  Model Mimarisi")
    st.success("Algoritma: **Multinomial Naive Bayes**")
    st.warning("Teknik: **TF-IDF (Bigram)**")
    st.error("EÄŸitim: **Full Hibrit (3 SÄ±nÄ±f Sentetik)**")

# --- 3. MODELÄ° HAZIRLA ---
yasakli_kelimeler = [
    "gÃ¼ldÃ¼m", "haha", "hahaha", "jsjsjs", "lol", 
    "ya", "ÅŸey", "bir", "bu", "ÅŸu", "o", "ben", "sen",
    "kadar", "gibi", "iÃ§in", "diye", "gidip"
]

# --- SENTETÄ°K VERÄ° SETLERÄ° ---

# A) SENTETÄ°K NÃ–TRLER
sentetik_notrler = [
    "toplantÄ± yarÄ±n saat 14:00'te yapÄ±lacak", "bugÃ¼n hava durumu parÃ§alÄ± bulutlu",
    "yarÄ±n okula gideceÄŸim", "markete gidip ekmek alacaÄŸÄ±m",
    "otobÃ¼s duraÄŸÄ±nda bekliyorum", "akÅŸam yemeÄŸi iÃ§in makarna yaptÄ±m",
    "telefonumun ÅŸarjÄ± bitti", "kitap okuyorum", "televizyon izliyorum",
    "bilgisayar baÅŸÄ±nda Ã§alÄ±ÅŸÄ±yorum", "sÄ±nav haftasÄ± baÅŸladÄ±", "ders Ã§alÄ±ÅŸmam lazÄ±m",
    "bugÃ¼n gÃ¼nlerden salÄ±", "hava biraz soÄŸuk", "kargo paketim geldi",
    "sipariÅŸ durumu kargoda", "banka hesabÄ± aÃ§tÄ±rdÄ±m", "doktordan randevu aldÄ±m",
    "tÃ¼rkiye'nin baÅŸkenti ankara'dÄ±r", "istanbul en kalabalÄ±k ÅŸehirdir",
    "nÃ¼fusu 5 milyondan fazladÄ±r", "coÄŸrafya dersinde bÃ¶lgeleri iÅŸledik",
    "tÃ¼rkiye bir yarÄ±madadÄ±r", "su 100 derecede kaynar",
    "dÃ¼nya gÃ¼neÅŸ etrafÄ±nda dÃ¶ner", "matematik sÄ±navÄ± zor deÄŸildi"
] * 20

# B) SENTETÄ°K NEGATÄ°FLER
sentetik_negatifler = [
    "film o kadar sÄ±kÄ±cÄ±ydÄ± ki yarÄ±sÄ±nda Ã§Ä±ktÄ±m",
    "Ã§ok sÄ±kÄ±cÄ± bir gÃ¼ndÃ¼ hiÃ§ keyif alamadÄ±m",
    "mekanÄ± terk ettim Ã§Ã¼nkÃ¼ Ã§ok kÃ¶tÃ¼ydÃ¼",
    "ortam o kadar gergindi ki terk ettim",
    "bu Ã¼rÃ¼n tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ±",
    "beklediÄŸimden Ã§ok daha kÃ¶tÃ¼ Ã§Ä±ktÄ±",
    "hiÃ§ beÄŸenmedim param boÅŸa gitti",
    "servis rezaletti bir daha asla gitmem",
    "tadÄ± iÄŸrenÃ§ti midem bulandÄ±",
    "bu ne biÃ§im hizmet, yazÄ±klar olsun"
] * 20

# C) SENTETÄ°K POZÄ°TÄ°FLER
sentetik_pozitifler = [
    "tamam Ã§ocuk dersin adÄ±nÄ± ve iÃ§eriÄŸini kavramÄ±ÅŸ",
    "konuyu Ã§ok iyi anladÄ±m ve kavradÄ±m",
    "Ã¶ÄŸrenci dersi baÅŸarÄ±yla geÃ§ti tebrikler",
    "projenin mantÄ±ÄŸÄ±nÄ± hemen kavramÄ±ÅŸ",
    "dersin iÃ§eriÄŸi Ã§ok zengin ve Ã¶ÄŸreticiydi",
    "Ã§ocuklar konuyu hemen anladÄ± harikalar",
    "bu derste Ã§ok ÅŸey Ã¶ÄŸrendim teÅŸekkÃ¼rler",
    "sÄ±navdan yÃ¼ksek not aldÄ±m Ã§ok mutluyum",
    "baÅŸarÄ±lÄ± bir Ã§alÄ±ÅŸma olmuÅŸ eline saÄŸlÄ±k",
    "tamamdÄ±r bu iÅŸ olmuÅŸ gayet gÃ¼zel",
    "anlatÄ±lan her ÅŸeyi eksiksiz kavramÄ±ÅŸ",
    "performansÄ± gayet yerinde tebrik ediyorum"
] * 30

@st.cache_resource
def modeli_egit():
    try:
        # Dosya 1
        df1 = pd.read_csv('TÃ¼rkÃ§e Tweetlerde Analiz(Etiketli).csv', encoding='utf-8')
        df1.dropna(subset=['Tweet'], inplace=True)
        map1 = {'Negatif': 0, 'NÃ¶tr': 1, 'Pozitif': 2}
        df1['label'] = df1['Etiket'].map(map1)
        df1 = df1[['Tweet', 'label']].rename(columns={'Tweet': 'text'})

        # Dosya 2
        df2 = pd.read_csv('sentimentSet.csv', encoding='utf-8')
        df2.dropna(subset=['tweets'], inplace=True)
        map2 = {-1: 0, 0: 1, 1: 2}
        df2['label'] = df2['sentiment'].map(map2)
        df2 = df2[['tweets', 'label']].rename(columns={'tweets': 'text'})

        df_final = pd.concat([df1, df2], ignore_index=True)
        
        def temizle(text):
            text = str(text).lower()
            text = re.sub(r'https?://\S+|www\.\S+', '', text)
            text = re.sub(r'[^\w\s]', '', text)
            text = re.sub(r'\d+', '', text)
            return text
        
        df_final['clean_text'] = df_final['text'].apply(temizle)
        df_final.dropna(subset=['label'], inplace=True)
        df_final['label'] = df_final['label'].astype(int)
        
        # TÃœM SENTETÄ°K VERÄ°LERÄ° BÄ°RLEÅTÄ°R
        df_synth_neu = pd.DataFrame({'clean_text': sentetik_notrler, 'label': 1})
        df_synth_neg = pd.DataFrame({'clean_text': sentetik_negatifler, 'label': 0})
        df_synth_pos = pd.DataFrame({'clean_text': sentetik_pozitifler, 'label': 2})
        
        df_final = pd.concat([df_final, df_synth_neu, df_synth_neg, df_synth_pos], ignore_index=True)

    except FileNotFoundError:
        st.error("HATA: CSV dosyalarÄ± bulunamadÄ±!")
        st.stop()

    # Dengeleme
    min_sayi = df_final['label'].value_counts().min()
    df_dengeli = pd.concat([
        df_final[df_final['label'] == 0].sample(n=min_sayi, random_state=42),
        df_final[df_final['label'] == 1].sample(n=min_sayi, random_state=42),
        df_final[df_final['label'] == 2].sample(n=min_sayi, random_state=42)
    ])

    # EÄŸitim
    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=yasakli_kelimeler)
    X_vec = vectorizer.fit_transform(df_dengeli['clean_text'])
    y = df_dengeli['label']
    model = MultinomialNB()
    model.fit(X_vec, y)
    
    return model, vectorizer

# Modeli Sessizce YÃ¼kle
with st.spinner('Sistem BaÅŸlatÄ±lÄ±yor: Veriler Okunuyor ve Model AnlÄ±k Olarak EÄŸitiliyor...'):
    model, vectorizer = modeli_egit()

# --- 4. ANA EKRAN TASARIMI ---
st.markdown("<h1 class='main-title'>GerÃ§ek ZamanlÄ± Ã–rÃ¼ntÃ¼ TanÄ±ma ve Duygu Analizi</h1>", unsafe_allow_html=True)
st.markdown("<p class='sub-title'>Hibrit Veri ile EÄŸitilen Dinamik NLP Modeli</p>", unsafe_allow_html=True)
st.write("---")

if 'metin' not in st.session_state:
    st.session_state['metin'] = ""

col_input, col_result = st.columns([1.5, 1])

with col_input:
    st.subheader("ğŸ“ Metin GiriÅŸi")
    
    st.markdown("**HÄ±zlÄ± Test Verisi:**")
    btn_col1, btn_col2, btn_col3 = st.columns(3)
    
    if btn_col1.button("ğŸ˜¡ Negatif"):
        st.session_state['metin'] = "Film o kadar sÄ±kÄ±cÄ±ydÄ± ki yarÄ±sÄ±nda salonu terk ettim."
    if btn_col2.button("ğŸ˜ NÃ¶tr"):
        st.session_state['metin'] = "TÃ¼rkiye'nin baÅŸkenti Ankara'dÄ±r ve nÃ¼fusu 5 milyondan fazladÄ±r."
    if btn_col3.button("ğŸ˜Š Pozitif"):
        st.session_state['metin'] = "Tamam, Ã§ocuk dersin adÄ±nÄ± ve iÃ§eriÄŸini kavramÄ±ÅŸ."
        
    tweet_input = st.text_area("Analiz kutusu:", value=st.session_state['metin'], height=150, placeholder="Analiz edilecek metni buraya giriniz...")
    analyze_btn = st.button("ğŸš€ ANALÄ°Z ET", type="primary")

with col_result:
    st.subheader("ğŸ“Š Ã–rÃ¼ntÃ¼ Sonucu")
    
    if analyze_btn and tweet_input:
        text = str(tweet_input).lower()
        text = re.sub(r'https?://\S+|www\.\S+', '', text)
        text = re.sub(r'[^\w\s]', '', text)
        text = re.sub(r'\d+', '', text)
        
        vektor = vectorizer.transform([text])
        tahmin = model.predict(vektor)[0]
        
        # SonuÃ§ KartlarÄ±
        if tahmin == 2: # POZÄ°TÄ°F
            st.markdown("""
            <div class="result-card" style="background-color: #d4edda; color: #155724; border: 2px solid #c3e6cb;">
                <h1>ğŸ˜Š<br>POZÄ°TÄ°F</h1>
                <p>Tespit Edilen Ã–rÃ¼ntÃ¼: <b>Olumlu / BaÅŸarÄ±lÄ±</b></p>
            </div>
            """, unsafe_allow_html=True)
            st.balloons()
            
        elif tahmin == 0: # NEGATÄ°F
            st.markdown("""
            <div class="result-card" style="background-color: #f8d7da; color: #721c24; border: 2px solid #f5c6cb;">
                <h1>ğŸ˜¡<br>NEGATÄ°F</h1>
                <p>Tespit Edilen Ã–rÃ¼ntÃ¼: <b>Olumsuz / Åikayet</b></p>
            </div>
            """, unsafe_allow_html=True)
            
        else: # NÃ–TR
            st.markdown("""
            <div class="result-card" style="background-color: #fff3cd; color: #856404; border: 2px solid #ffeeba;">
                <h1>ğŸ˜<br>NÃ–TR</h1>
                <p>Tespit Edilen Ã–rÃ¼ntÃ¼: <b>Durum Bildirimi / Bilgi</b></p>
            </div>
            """, unsafe_allow_html=True)
            
        with st.expander("ğŸ” Modelin GÃ¶rdÃ¼ÄŸÃ¼ Ä°ÅŸlenmiÅŸ Veri"):
            st.code(text, language="text")

    elif analyze_btn:
        st.warning("LÃ¼tfen analiz edilecek bir metin giriniz.")
    else:
        st.info("Sistem hazÄ±r. Sol taraftan veri giriÅŸi yapabilirsiniz.")