{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffcf70-3841-4db9-a905-85646cc6a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veriler yÃ¼kleniyor...\n",
      "Ä°ki veri seti birleÅŸtirildi.\n",
      "\n",
      "Modeli gÃ¼Ã§lendirmek iÃ§in KAPSAMLI ZOR Ã–RNEKLER ekleniyor...\n",
      "\n",
      "Genel Veri ArtÄ±rma (Random Swap) BaÅŸlÄ±yor...\n",
      "\n",
      "Veri EÄŸitim ve Test setlerine ayrÄ±lÄ±yor...\n",
      "VektÃ¶rleÅŸtirici eÄŸitiliyor...\n",
      "Model eÄŸitiliyor...\n",
      "\n",
      "Model baÅŸarÄ± metrikleri hesaplanÄ±yor...\n",
      "Model DoÄŸruluÄŸu (Accuracy): 0.9688\n",
      "\n",
      "SÄ±nÄ±flandÄ±rma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.93      0.99      0.96       770\n",
      "        NÃ¶tr       0.99      0.96      0.98       770\n",
      "     Pozitif       0.98      0.96      0.97       770\n",
      "\n",
      "    accuracy                           0.97      2310\n",
      "   macro avg       0.97      0.97      0.97      2310\n",
      "weighted avg       0.97      0.97      0.97      2310\n",
      "\n",
      "\n",
      "ğŸ‰ MÃœKEMMEL! Model artÄ±k daha fazla zor Ã¶rneÄŸi doÄŸru sÄ±nÄ±flandÄ±rmak iÃ§in eÄŸitildi.\n",
      "Test DoÄŸruluÄŸu: 96.88%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "# --- 1. VERÄ° YÃœKLEME ---\n",
    "print(\"Veriler yÃ¼kleniyor...\")\n",
    "try:\n",
    "    # Dosya 1\n",
    "    df1 = pd.read_csv('TÃ¼rkÃ§e Tweetlerde Analiz(Etiketli).csv', encoding='utf-8')\n",
    "    df1.dropna(subset=['Tweet'], inplace=True)\n",
    "    \n",
    "    # KRÄ°TÄ°K DÃœZELTME: ETÄ°KET HARÄ°TALAMASINI TERS Ã‡EVÄ°RÄ°YORUZ (app.py beklentisine gÃ¶re)\n",
    "    # Pozitif -> 2, Negatif -> 0, NÃ¶tr -> 1 (Bu, app.py'deki ters eÅŸleÅŸmeyi dÃ¼zeltir)\n",
    "    map1 = {'Negatif': 0, 'NÃ¶tr': 1, 'Pozitif': 2} \n",
    "    df1['Etiket_Sayisal'] = df1['Etiket'].map(map1)\n",
    "    df1.rename(columns={'Tweet': 'Metin'}, inplace=True)\n",
    "    df1 = df1[['Metin', 'Etiket_Sayisal']]\n",
    "\n",
    "    # Dosya 2\n",
    "    try:\n",
    "        df2 = pd.read_csv('sentimentSet.csv', encoding='utf-8', header=None)\n",
    "        df2.columns = ['Etiket', 'Metin']\n",
    "        # KRÄ°TÄ°K DÃœZELTME: Ä°kinci dosya etiketlerini de aynÄ± ÅŸekilde Ã§eviriyoruz.\n",
    "        # -1=Negatif (0), 1=Pozitif (2)\n",
    "        map2 = {-1: 0, 0: 1, 1: 2} \n",
    "        df2['Etiket_Sayisal'] = df2['Etiket'].map(map2)\n",
    "        df2 = df2[['Metin', 'Etiket_Sayisal']].dropna()\n",
    "        df_final = pd.concat([df1, df2], ignore_index=True)\n",
    "        print(\"Ä°ki veri seti birleÅŸtirildi.\")\n",
    "    except FileNotFoundError:\n",
    "        df_final = df1\n",
    "        print(\"Sadece tek veri seti kullanÄ±lÄ±yor.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"HATA: CSV dosyalarÄ± bulunamadÄ±!\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. TEMÄ°ZLÄ°K ---\n",
    "def temizle_metin(metin):\n",
    "    metin = str(metin).lower()\n",
    "    metin = re.sub(r'http\\S+|www\\S+', '', metin)\n",
    "    metin = re.sub(r'@[A-Za-z0-9]+', '', metin)\n",
    "    metin = re.sub(r'[^\\w\\s]', '', metin)\n",
    "    metin = re.sub(r'\\d+', '', metin)\n",
    "    return metin\n",
    "\n",
    "df_final['Temiz_Metin'] = df_final['Metin'].apply(temizle_metin)\n",
    "df_final = df_final[df_final['Temiz_Metin'].str.len() > 3]\n",
    "\n",
    "# ========================================================\n",
    "# --- 3. ZOR Ã–RNEK EÄÄ°TÄ°MÄ° (HARD MINING - GÃœÃ‡LENDÄ°RÄ°LDÄ°) ---\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\nModeli gÃ¼Ã§lendirmek iÃ§in KAPSAMLI ZOR Ã–RNEKLER ekleniyor...\")\n",
    "\n",
    "# A) ZOR NEGATÄ°FLER (Etiket: 0) \n",
    "negatif_zor_ornekler = [\n",
    "    # Genel Tuzaklar ve PiÅŸmanlÄ±k\n",
    "    (\"aldÄ±m ama hiÃ§ memnun kalmadÄ±m\", 0),\n",
    "    (\"Ã¼rÃ¼n gÃ¼zel gÃ¶rÃ¼nÃ¼yor ama performansÄ± berbat\", 0),\n",
    "    (\"hevesle aldÄ±m ama bozuk Ã§Ä±ktÄ±\", 0),\n",
    "    (\"beklentim yÃ¼ksekti ama hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸradÄ±m\", 0),\n",
    "    (\"asla tavsiye etmiyorum piÅŸman oldum\", 0),\n",
    "    (\"paramÄ± kaybettim Ã§ok Ã¼zgÃ¼nÃ¼m\", 0), \n",
    "    (\"para kaybettim\", 0),\n",
    "    (\"bence haksÄ±zsÄ±n\", 0), \n",
    "    \n",
    "    # AKADEMÄ°K/SOSYAL HAYAT ÅÄ°KAYETLERÄ° (GÃœÃ‡LENDÄ°RÄ°LDÄ°)\n",
    "    (\"iÅŸletim sistemleri dersi berbat geÃ§iyor\", 0),\n",
    "    (\"en sevdiÄŸim yazar Ã¶ldÃ¼\", 0),\n",
    "    (\"kedileri sevmiyorum\", 0),\n",
    "    (\"yine sÄ±navdan kÃ¶tÃ¼ not aldÄ±m her ÅŸey Ã§ok zor\", 0),\n",
    "    (\"okulun yemekhanesi iÄŸrenÃ§ olmuÅŸ\", 0),\n",
    "    (\"bu havada dÄ±ÅŸarÄ± Ã§Ä±kmak tam bir eziyet\", 0),\n",
    "    \n",
    "    # YENÄ° EKLEMELER\n",
    "    (\"hizmet Ã§ok yavaÅŸtÄ± beklediÄŸime deÄŸmedi\", 0),\n",
    "    (\"sadece hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸradÄ±m param Ã§Ã¶pe gitti\", 0),\n",
    "    (\"bÃ¶yle bir hata kabul edilemez ÅŸikayetÃ§iyim\", 0),\n",
    "    (\"keÅŸke almasaydÄ±m ÅŸimdi ne yapacaÄŸÄ±m\", 0),\n",
    "    (\"gÃ¼nÃ¼m Ã§ok kÃ¶tÃ¼ geÃ§ti Ã§ok yoruldum\", 0),\n",
    "    (\"yine aynÄ± problemi yaÅŸadÄ±m sinir bozucu\", 0),\n",
    "    (\"tadilat iÅŸleri bitmedi gÃ¼rÃ¼ltÃ¼den durulmuyor\", 0),\n",
    "    \n",
    "    # KÃœLTÃœR & SANAT (KÃ¶tÃ¼)\n",
    "    (\"bu kitap tam bir vakit kaybÄ±ydÄ± sakÄ±n okumayÄ±n\", 0),\n",
    "    (\"filmin senaryosu Ã§ok saÃ§maydÄ± yarÄ±sÄ±nda Ã§Ä±ktÄ±m\", 0),\n",
    "    (\"roman beni hiÃ§ sarmadÄ± dili Ã§ok aÄŸÄ±rdÄ±\", 0),\n",
    "    (\"yazarÄ±n anlatÄ±mÄ± Ã§ok sÄ±kÄ±cÄ± uykum geldi\", 0),\n",
    "    (\"verdiÄŸim paraya acÄ±dÄ±m berbat bir eser\", 0),\n",
    "    (\"dizinin finali tam bir fiyaskoydu\", 0),\n",
    "    (\"oyunculuklar iyiydi ama kurgu felaketti\", 0),\n",
    "    (\"eser o kadar sÄ±kÄ±cÄ±ydÄ± ki kendimi zorladÄ±m\", 0)\n",
    "]\n",
    "\n",
    "# B) ZOR NÃ–TRLER (Etiket: 1)\n",
    "notr_zor_ornekler = [\n",
    "    # Genel ve Kurumsal Bilgi (GÃœÃ‡LENDÄ°RÄ°LDÄ°)\n",
    "    (\"tÃ¼rkiyenin baÅŸkenti ankaradÄ±r\", 1),\n",
    "    (\"bugÃ¼n hava 25 derece\", 1),\n",
    "    (\"sipariÅŸiniz kargoya teslim edilmiÅŸtir\", 1),\n",
    "    (\"kargonuz yola Ã§Ä±kmÄ±ÅŸtÄ±r takip numarasÄ± ÅŸudur\", 1),\n",
    "    (\"sipariÅŸiniz baÅŸarÄ±yla oluÅŸturuldu\", 1),\n",
    "    (\"Ã¼rÃ¼nÃ¼nÃ¼z daÄŸÄ±tÄ±ma Ã§Ä±karÄ±ldÄ±\", 1),\n",
    "    (\"kargo teslimat ÅŸubesinde bekliyor\", 1),\n",
    "    (\"sipariÅŸ durumu gÃ¼ncellendi\", 1),\n",
    "    (\"toplantÄ± yarÄ±n saat ikide yapÄ±lacak\", 1),\n",
    "    (\"banka havalesi bir iÅŸ gÃ¼nÃ¼ iÃ§inde gerÃ§ekleÅŸecektir\", 1),\n",
    "    (\"proje raporu pazartesi gÃ¼nÃ¼ teslim edilecek\", 1),\n",
    "    (\"sunum iÃ§in gerekli slaytlar hazÄ±rdÄ±r\", 1),\n",
    "    \n",
    "    # AKADEMÄ°K VE TEKNÄ°K BÄ°LGÄ° (GÃœÃ‡LENDÄ°RÄ°LDÄ°)\n",
    "    (\"iÅŸletim sistemleri dersindeyiz\", 1), \n",
    "    (\"bugÃ¼n proje teslim edilecek\", 1),\n",
    "    (\"fizik sÄ±navÄ±nÄ±n sonuÃ§larÄ± aÃ§Ä±klandÄ±\", 1),\n",
    "    (\"Ã¶nÃ¼mÃ¼zdeki hafta sunum yapacaÄŸÄ±m\", 1),\n",
    "    (\"bu kitap 19. yÃ¼zyÄ±l rus edebiyatÄ±nÄ±n Ã¶nemli eserlerinden biridir\", 1),\n",
    "    (\"dostoyevski suÃ§ ve ceza romanÄ±nÄ± yazmÄ±ÅŸtÄ±r\", 1),\n",
    "    (\"film iki saat sÃ¼rÃ¼yor ve baÅŸrol oyuncusu ahmettir\", 1),\n",
    "    (\"roman karakterleri gerÃ§ek hayattan esinlenilmiÅŸtir\", 1),\n",
    "    (\"yazarÄ±n son kitabÄ± geÃ§en hafta raflardaki yerini aldÄ±\", 1),\n",
    "    (\"mÃ¼ze pazartesi gÃ¼nleri kapalÄ±dÄ±r\", 1),\n",
    "    (\"tiyatro oyunu Ã¼Ã§ perdeden oluÅŸuyor\", 1),\n",
    "    (\"sistem arayÃ¼zÃ¼ gÃ¼ncellenmiÅŸtir\", 1),\n",
    "    (\"yeni versiyonda hata dÃ¼zeltmeleri yapÄ±ldÄ±\", 1),\n",
    "    \n",
    "    # YENÄ° EKLEMELER\n",
    "    (\"sonuÃ§lar bugÃ¼n akÅŸam aÃ§Ä±klanacak\", 1),\n",
    "    (\"internet baÄŸlantÄ±mÄ±z geÃ§ici olarak kesilmiÅŸtir\", 1),\n",
    "    (\"ÅŸirketin yeni vizyon toplantÄ±sÄ± salÄ± gÃ¼nÃ¼ yapÄ±lacak\", 1),\n",
    "    (\"biletler online satÄ±ÅŸa aÃ§Ä±ldÄ±\", 1),\n",
    "    (\"Ã¼rÃ¼n kullanÄ±m kÄ±lavuzu kutu iÃ§inden Ã§Ä±kmadÄ±\", 1),\n",
    "    (\"havaalanÄ± transferi iÃ§in rezervasyon yaptÄ±rdÄ±m\", 1),\n",
    "    (\"bu konudaki yasal dÃ¼zenlemeler deÄŸiÅŸti\", 1),\n",
    "    (\"web sitesinde gÃ¼ncelleme Ã§alÄ±ÅŸmasÄ± yapÄ±lÄ±yor\", 1),\n",
    "]\n",
    "\n",
    "# C) ZOR POZÄ°TÄ°FLER (Etiket: 2) \n",
    "pozitif_zor_ornekler = [\n",
    "    # Genel Tuzaklar\n",
    "    (\"hiÃ§ fena deÄŸil bayÄ±ldÄ±m\", 2), \n",
    "    (\"sorunsuz bir ÅŸekilde elime ulaÅŸtÄ±\", 2),\n",
    "    (\"bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ya da kÃ¼Ã§Ã¼klÃ¼ÄŸÃ¼ Ã¶nemli deÄŸil bir nimettir\", 2),\n",
    "    (\"filmin senaryosu ve oyunculuklar muazzamdÄ±\", 2),\n",
    "    (\"muazzam bir iÅŸ Ã§Ä±karmÄ±ÅŸlar tebrikler\", 2),\n",
    "    (\"gerÃ§ekten muazzam bir performanstÄ±\", 2),\n",
    "    (\"senaryo muazzam oyunculuk harika\", 2),\n",
    "    (\"Ã¶nemli deÄŸil demek her zaman kÃ¶tÃ¼ deÄŸildir\", 2),\n",
    "    (\"ÅŸartlar ne olursa olsun sahip olmak bÃ¼yÃ¼k nimet\", 2),\n",
    "    (\"korkunÃ§ gÃ¼zel bir filmdi\", 2),\n",
    "    (\"yok bÃ¶yle bir lezzet\", 2),\n",
    "    (\"bundan daha iyisi mezarda\", 2),\n",
    "    \n",
    "    # Yeni Eklenenler (Finans, Sevgi, BaÅŸarÄ±)\n",
    "    (\"para kazandÄ±m Ã§ok mutluyum\", 2), \n",
    "    (\"para kazandÄ±m\", 2), \n",
    "    (\"bÃ¼yÃ¼k bir Ã§ekiliÅŸ kazandÄ±m\", 2),\n",
    "    (\"borsada iyi kazanÃ§ elde ettim\", 2),\n",
    "    (\"kedileri severim\", 2), \n",
    "    (\"hayvanlarÄ± Ã§ok severim\", 2),\n",
    "    (\"kÃ¶pekleri seviyorum\", 2),\n",
    "    \n",
    "    # KÃœLTÃœR & SANAT (Ä°yi)\n",
    "    (\"bu kitap bir baÅŸyapÄ±t mutlaka okunmalÄ±\", 2),\n",
    "    (\"hayatÄ±mda izlediÄŸim en etkileyici filmdi\", 2),\n",
    "    (\"yazarÄ±n kalemine hayran kaldÄ±m soluksuz okudum\", 2),\n",
    "    (\"kitabÄ± elimden bÄ±rakamadÄ±m bir gÃ¼nde bitti\", 2),\n",
    "    (\"karakterlerin derinliÄŸi ve kurgu muazzamdÄ±\", 2),\n",
    "    (\"senaryo o kadar iyiydi ki ayakta alkÄ±ÅŸladÄ±m\", 2),\n",
    "    (\"uygulamanÄ±n arayÃ¼zÃ¼ Ã§ok kullanÄ±ÅŸlÄ± ve modern olmuÅŸ\", 2),\n",
    "    (\"yeni tasarÄ±m harika gÃ¶rÃ¼nÃ¼yor ellerinize saÄŸlÄ±k\", 2),\n",
    "    (\"arayÃ¼z Ã§ok ÅŸÄ±k ve hÄ±zlÄ± Ã§alÄ±ÅŸÄ±yor\", 2),\n",
    "    (\"kullanÄ±cÄ± dostu bir tasarÄ±m olmuÅŸ bayÄ±ldÄ±m\", 2),\n",
    "    (\"arayÃ¼zÃ¼ Ã§ok beÄŸendim Ã§ok pratik\", 2),\n",
    "    (\"mÃ¼ÅŸteri hizmetleri Ã§ok ilgiliydi sorunumu hemen Ã§Ã¶zdÃ¼ler\", 2),\n",
    "    (\"yaÅŸadÄ±ÄŸÄ±m sorun anÄ±nda giderildi teÅŸekkÃ¼rler\", 2),\n",
    "    (\"sorunum kÄ±sa sÃ¼rede Ã§Ã¶zÃ¼ldÃ¼ harika hizmet\", 2),\n",
    "    (\"destek ekibi Ã§ok yardÄ±mcÄ± oldu sorun kalmadÄ±\", 2),\n",
    "    (\"ÅŸikayetimle hemen ilgilendiler bravo\", 2),\n",
    "    (\"sorunumu Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼z iÃ§in teÅŸekkÃ¼r ederim\", 2)\n",
    "]\n",
    "\n",
    "\n",
    "# Listeleri DataFrame yap\n",
    "df_neg_zor = pd.DataFrame(negatif_zor_ornekler, columns=['Metin', 'Etiket_Sayisal'])\n",
    "df_notr_zor = pd.DataFrame(notr_zor_ornekler, columns=['Metin', 'Etiket_Sayisal'])\n",
    "df_poz_zor = pd.DataFrame(pozitif_zor_ornekler, columns=['Metin', 'Etiket_Sayisal'])\n",
    "\n",
    "# Temizlik uygula\n",
    "df_neg_zor['Temiz_Metin'] = df_neg_zor['Metin'].apply(temizle_metin)\n",
    "df_notr_zor['Temiz_Metin'] = df_notr_zor['Metin'].apply(temizle_metin)\n",
    "df_poz_zor['Temiz_Metin'] = df_poz_zor['Metin'].apply(temizle_metin)\n",
    "\n",
    "# Hepsini 50 kat aÄŸÄ±rlÄ±kla ana veriye ekle\n",
    "df_final = pd.concat([df_final] + \n",
    "                      [df_neg_zor] * 50 + \n",
    "                      [df_notr_zor] * 50 + \n",
    "                      [df_poz_zor] * 50, ignore_index=True)\n",
    "\n",
    "\n",
    "# --- 4. VERÄ° ARTIRMA VE DENGELEME (GARANTÄ°LÄ° YÃ–NTEM) ---\n",
    "print(\"\\nGenel Veri ArtÄ±rma (Random Swap) BaÅŸlÄ±yor...\")\n",
    "\n",
    "def veri_artir_swap(metin):\n",
    "    kelimeler = metin.split()\n",
    "    if len(kelimeler) < 4: return metin\n",
    "    idx1, idx2 = random.sample(range(len(kelimeler)), 2)\n",
    "    kelimeler[idx1], kelimeler[idx2] = kelimeler[idx2], kelimeler[idx1]\n",
    "    return \" \".join(kelimeler)\n",
    "\n",
    "sinif_dagilimi = df_final['Etiket_Sayisal'].value_counts()\n",
    "hedef_sayi = sinif_dagilimi.max()\n",
    "\n",
    "tum_veriler = []\n",
    "for etiket in sinif_dagilimi.index:\n",
    "    df_sinif = df_final[df_final['Etiket_Sayisal'] == etiket].copy()\n",
    "    tum_veriler.append(df_sinif)\n",
    "    \n",
    "    mevcut_sayi = len(df_sinif)\n",
    "    if mevcut_sayi < hedef_sayi:\n",
    "        eksik = hedef_sayi - mevcut_sayi\n",
    "        kaynak = df_sinif['Temiz_Metin'].sample(n=eksik, replace=True, random_state=42).tolist()\n",
    "        yeni = [veri_artir_swap(m) for m in kaynak]\n",
    "        \n",
    "        df_yeni = pd.DataFrame({\n",
    "            'Metin': kaynak,\n",
    "            'Etiket_Sayisal': [etiket] * len(yeni),\n",
    "            'Temiz_Metin': yeni\n",
    "        })\n",
    "        tum_veriler.append(df_yeni)\n",
    "\n",
    "df_dengeli = pd.concat(tum_veriler, ignore_index=True)\n",
    "# KarÄ±ÅŸtÄ±r\n",
    "df_dengeli = df_dengeli.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 5. VERÄ° AYIRMA VE EÄÄ°TÄ°M ---\n",
    "print(\"\\nVeri EÄŸitim ve Test setlerine ayrÄ±lÄ±yor...\")\n",
    "\n",
    "# Veriyi ayÄ±r\n",
    "X = df_dengeli['Temiz_Metin']\n",
    "y = df_dengeli['Etiket_Sayisal']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) \n",
    "\n",
    "# VektÃ¶rleÅŸtiriciyi SADECE eÄŸitim verisi Ã¼zerinde eÄŸit\n",
    "print(\"VektÃ¶rleÅŸtirici eÄŸitiliyor...\")\n",
    "# KRÄ°TÄ°K DÃœZELTME: Ã–zellik sayÄ±sÄ±nÄ± artÄ±rÄ±yoruz.\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Modeli eÄŸit\n",
    "print(\"Model eÄŸitiliyor...\")\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# --- 6. METRÄ°K HESAPLAMA ---\n",
    "print(\"\\nModel baÅŸarÄ± metrikleri hesaplanÄ±yor...\")\n",
    "\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model DoÄŸruluÄŸu (Accuracy): {accuracy:.4f}\")\n",
    "\n",
    "# Etiketler ters Ã§evrildiÄŸi iÃ§in, sÄ±nÄ±flandÄ±rma raporu etiketlerini de ters Ã§eviriyoruz.\n",
    "print(\"\\nSÄ±nÄ±flandÄ±rma Raporu:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negatif', 'NÃ¶tr', 'Pozitif']))\n",
    "\n",
    "# --- 7. MODEL KAYDI ---\n",
    "joblib.dump(model, 'final_model.pkl')\n",
    "joblib.dump(vectorizer, 'final_vectorizer.pkl')\n",
    "\n",
    "print(\"\\nğŸ‰ MÃœKEMMEL! Model artÄ±k daha fazla zor Ã¶rneÄŸi doÄŸru sÄ±nÄ±flandÄ±rmak iÃ§in eÄŸitildi.\")\n",
    "print(f\"Test DoÄŸruluÄŸu: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156ecb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
