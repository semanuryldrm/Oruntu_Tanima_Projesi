{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffcf70-3841-4db9-a905-85646cc6a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veriler yÃ¼kleniyor...\n",
      "Ä°ki veri seti birleÅŸtirildi.\n",
      "\n",
      "Modeli gÃ¼Ã§lendirmek iÃ§in KAPSAMLI ZOR Ã–RNEKLER ekleniyor...\n",
      "\n",
      "Genel Veri ArtÄ±rma (Random Swap) BaÅŸlÄ±yor...\n",
      "\n",
      "Model eÄŸitiliyor...\n",
      "\n",
      "ğŸ‰ MÃœKEMMEL! Model artÄ±k her konuyu (Kitap, Film, AlÄ±ÅŸveriÅŸ) Ã§ok daha iyi anlÄ±yor.\n",
      "'app.py' uygulamasÄ±nÄ± yeniden baÅŸlatÄ±p deneyebilirsin.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import joblib\n",
    "\n",
    "# --- 1. VERÄ° YÃœKLEME ---\n",
    "print(\"Veriler yÃ¼kleniyor...\")\n",
    "try:\n",
    "    # Dosya 1\n",
    "    df1 = pd.read_csv('TÃ¼rkÃ§e Tweetlerde Analiz(Etiketli).csv', encoding='utf-8')\n",
    "    df1.dropna(subset=['Tweet'], inplace=True)\n",
    "    map1 = {'Negatif': 0, 'NÃ¶tr': 1, 'Pozitif': 2}\n",
    "    df1['Etiket_Sayisal'] = df1['Etiket'].map(map1)\n",
    "    df1.rename(columns={'Tweet': 'Metin'}, inplace=True)\n",
    "    df1 = df1[['Metin', 'Etiket_Sayisal']]\n",
    "\n",
    "    # Dosya 2\n",
    "    try:\n",
    "        df2 = pd.read_csv('sentimentSet.csv', encoding='utf-8', header=None)\n",
    "        df2.columns = ['Etiket', 'Metin']\n",
    "        map2 = {-1: 0, 0: 1, 1: 2} \n",
    "        df2['Etiket_Sayisal'] = df2['Etiket'].map(map2)\n",
    "        df2 = df2[['Metin', 'Etiket_Sayisal']].dropna()\n",
    "        df_final = pd.concat([df1, df2], ignore_index=True)\n",
    "        print(\"Ä°ki veri seti birleÅŸtirildi.\")\n",
    "    except FileNotFoundError:\n",
    "        df_final = df1\n",
    "        print(\"Sadece tek veri seti kullanÄ±lÄ±yor.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"HATA: CSV dosyalarÄ± bulunamadÄ±!\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. TEMÄ°ZLÄ°K ---\n",
    "def temizle_metin(metin):\n",
    "    metin = str(metin).lower()\n",
    "    metin = re.sub(r'http\\S+|www\\S+', '', metin)\n",
    "    metin = re.sub(r'@[A-Za-z0-9]+', '', metin)\n",
    "    metin = re.sub(r'[^\\w\\s]', '', metin)\n",
    "    metin = re.sub(r'\\d+', '', metin)\n",
    "    return metin\n",
    "\n",
    "df_final['Temiz_Metin'] = df_final['Metin'].apply(temizle_metin)\n",
    "df_final = df_final[df_final['Temiz_Metin'].str.len() > 3]\n",
    "\n",
    "# ========================================================\n",
    "# --- 3. ZOR Ã–RNEK EÄÄ°TÄ°MÄ° (HARD MINING - KÃœLTÃœR & GENEL) ---\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\nModeli gÃ¼Ã§lendirmek iÃ§in KAPSAMLI ZOR Ã–RNEKLER ekleniyor...\")\n",
    "\n",
    "# A) ZOR NEGATÄ°FLER (\"Ama\" tuzaklarÄ± + KÃ¶tÃ¼ Kitap/Film YorumlarÄ±)\n",
    "negatif_zor_ornekler = [\n",
    "    # Genel Tuzaklar\n",
    "    (\"aldÄ±m ama hiÃ§ memnun kalmadÄ±m\", 0),\n",
    "    (\"Ã¼rÃ¼n gÃ¼zel gÃ¶rÃ¼nÃ¼yor ama performansÄ± berbat\", 0),\n",
    "    (\"hevesle aldÄ±m ama bozuk Ã§Ä±ktÄ±\", 0),\n",
    "    (\"beklentim yÃ¼ksekti ama hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸradÄ±m\", 0),\n",
    "    (\"asla tavsiye etmiyorum piÅŸman oldum\", 0),\n",
    "    # KÃœLTÃœR & SANAT (KÃ¶tÃ¼)\n",
    "    (\"bu kitap tam bir vakit kaybÄ±ydÄ± sakÄ±n okumayÄ±n\", 0),\n",
    "    (\"filmin senaryosu Ã§ok saÃ§maydÄ± yarÄ±sÄ±nda Ã§Ä±ktÄ±m\", 0),\n",
    "    (\"roman beni hiÃ§ sarmadÄ± dili Ã§ok aÄŸÄ±rdÄ±\", 0),\n",
    "    (\"yazarÄ±n anlatÄ±mÄ± Ã§ok sÄ±kÄ±cÄ± uykum geldi\", 0),\n",
    "    (\"verdiÄŸim paraya acÄ±dÄ±m berbat bir eser\", 0),\n",
    "    (\"dizinin finali tam bir fiyaskoydu\", 0)\n",
    "]\n",
    "\n",
    "# B) ZOR NÃ–TRLER (Bilgi, Tarih, Kitap TanÄ±tÄ±mÄ± - Duygusuz)\n",
    "notr_zor_ornekler = [\n",
    "    # Genel Bilgi\n",
    "    (\"tÃ¼rkiyenin baÅŸkenti ankaradÄ±r\", 1),\n",
    "    (\"bugÃ¼n hava 25 derece\", 1),\n",
    "    (\"sipariÅŸiniz kargoya teslim edilmiÅŸtir\", 1),\n",
    "    (\"kargonuz yola Ã§Ä±kmÄ±ÅŸtÄ±r takip numarasÄ± ÅŸudur\", 1),\n",
    "    (\"sipariÅŸiniz baÅŸarÄ±yla oluÅŸturuldu\", 1),\n",
    "    (\"Ã¼rÃ¼nÃ¼nÃ¼z daÄŸÄ±tÄ±ma Ã§Ä±karÄ±ldÄ±\", 1),\n",
    "    (\"kargo teslimat ÅŸubesinde bekliyor\", 1),\n",
    "    (\"sipariÅŸ durumu gÃ¼ncellendi\", 1),\n",
    "    (\"toplantÄ± yarÄ±n saat ikide yapÄ±lacak\", 1),\n",
    "    # KÃœLTÃœR & SANAT (Bilgi)\n",
    "    (\"bu kitap 19. yÃ¼zyÄ±l rus edebiyatÄ±nÄ±n Ã¶nemli eserlerinden biridir\", 1),\n",
    "    (\"dostoyevski suÃ§ ve ceza romanÄ±nÄ± yazmÄ±ÅŸtÄ±r\", 1),\n",
    "    (\"film iki saat sÃ¼rÃ¼yor ve baÅŸrol oyuncusu ahmettir\", 1),\n",
    "    (\"roman karakterleri gerÃ§ek hayattan esinlenilmiÅŸtir\", 1),\n",
    "    (\"yazarÄ±n son kitabÄ± geÃ§en hafta raflardaki yerini aldÄ±\", 1),\n",
    "    (\"mÃ¼ze pazartesi gÃ¼nleri kapalÄ±dÄ±r\", 1),\n",
    "    (\"tiyatro oyunu Ã¼Ã§ perdeden oluÅŸuyor\", 1)\n",
    "]\n",
    "\n",
    "# C) ZOR POZÄ°TÄ°FLER (Ters KÃ¶ÅŸe Kelimeler + Ä°yi Kitap/Film YorumlarÄ±)\n",
    "pozitif_zor_ornekler = [\n",
    "    # Genel Tuzaklar\n",
    "    (\"hiÃ§ fena deÄŸil bayÄ±ldÄ±m\", 2), \n",
    "    (\"sorunsuz bir ÅŸekilde elime ulaÅŸtÄ±\", 2),\n",
    "    (\"bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ya da kÃ¼Ã§Ã¼klÃ¼ÄŸÃ¼ Ã¶nemli deÄŸil bir nimettir\", 2),\n",
    "    (\"filmin senaryosu ve oyunculuklar muazzamdÄ±\", 2),\n",
    "    (\"muazzam bir iÅŸ Ã§Ä±karmÄ±ÅŸlar tebrikler\", 2),\n",
    "    (\"gerÃ§ekten muazzam bir performanstÄ±\", 2),\n",
    "    (\"senaryo muazzam oyunculuk harika\", 2),\n",
    "    (\"Ã¶nemli deÄŸil demek her zaman kÃ¶tÃ¼ deÄŸildir\", 2),\n",
    "    (\"ÅŸartlar ne olursa olsun sahip olmak bÃ¼yÃ¼k nimet\", 2),\n",
    "    (\"korkunÃ§ gÃ¼zel bir filmdi\", 2),\n",
    "    (\"yok bÃ¶yle bir lezzet\", 2),\n",
    "    (\"bundan daha iyisi mezarda\", 2),\n",
    "    # KÃœLTÃœR & SANAT (Ä°yi)\n",
    "    (\"bu kitap bir baÅŸyapÄ±t mutlaka okunmalÄ±\", 2),\n",
    "    (\"hayatÄ±mda izlediÄŸim en etkileyici filmdi\", 2),\n",
    "    (\"yazarÄ±n kalemine hayran kaldÄ±m soluksuz okudum\", 2),\n",
    "    (\"kitabÄ± elimden bÄ±rakamadÄ±m bir gÃ¼nde bitti\", 2),\n",
    "    (\"karakterlerin derinliÄŸi ve kurgu muazzamdÄ±\", 2),\n",
    "    (\"senaryo o kadar iyiydi ki ayakta alkÄ±ÅŸladÄ±m\", 2),\n",
    "    # --- 1. GRUP: ARAYÃœZ VE TASARIM Ã–VGÃœLERÄ° ---\n",
    "    (\"uygulamanÄ±n arayÃ¼zÃ¼ Ã§ok kullanÄ±ÅŸlÄ± ve modern olmuÅŸ\", 2),\n",
    "    (\"yeni tasarÄ±m harika gÃ¶rÃ¼nÃ¼yor ellerinize saÄŸlÄ±k\", 2),\n",
    "    (\"arayÃ¼z Ã§ok ÅŸÄ±k ve hÄ±zlÄ± Ã§alÄ±ÅŸÄ±yor\", 2),\n",
    "    (\"kullanÄ±cÄ± dostu bir tasarÄ±m olmuÅŸ bayÄ±ldÄ±m\", 2),\n",
    "    (\"arayÃ¼zÃ¼ Ã§ok beÄŸendim Ã§ok pratik\", 2),\n",
    "    # --- 2. GRUP: MÃœÅTERÄ° HÄ°ZMETLERÄ° VE SORUN Ã‡Ã–ZME ---\n",
    "    (\"mÃ¼ÅŸteri hizmetleri Ã§ok ilgiliydi sorunumu hemen Ã§Ã¶zdÃ¼ler\", 2),\n",
    "    (\"yaÅŸadÄ±ÄŸÄ±m sorun anÄ±nda giderildi teÅŸekkÃ¼rler\", 2),\n",
    "    (\"sorunum kÄ±sa sÃ¼rede Ã§Ã¶zÃ¼ldÃ¼ harika hizmet\", 2),\n",
    "    (\"destek ekibi Ã§ok yardÄ±mcÄ± oldu sorun kalmadÄ±\", 2),\n",
    "    (\"ÅŸikayetimle hemen ilgilendiler bravo\", 2),\n",
    "    (\"sorunumu Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼z iÃ§in teÅŸekkÃ¼r ederim\", 2)\n",
    "]\n",
    "\n",
    "# Listeleri DataFrame yap\n",
    "df_neg_zor = pd.DataFrame(negatif_zor_ornekler, columns=['Metin', 'Etiket_Sayisal'])\n",
    "df_notr_zor = pd.DataFrame(notr_zor_ornekler, columns=['Metin', 'Etiket_Sayisal'])\n",
    "df_poz_zor = pd.DataFrame(pozitif_zor_ornekler, columns=['Metin', 'Etiket_Sayisal'])\n",
    "\n",
    "# Temizlik uygula\n",
    "df_neg_zor['Temiz_Metin'] = df_neg_zor['Metin'].apply(temizle_metin)\n",
    "df_notr_zor['Temiz_Metin'] = df_notr_zor['Metin'].apply(temizle_metin)\n",
    "df_poz_zor['Temiz_Metin'] = df_poz_zor['Metin'].apply(temizle_metin)\n",
    "\n",
    "# Hepsini 50 kat aÄŸÄ±rlÄ±kla ana veriye ekle\n",
    "df_final = pd.concat([df_final] + \n",
    "                     [df_neg_zor] * 50 + \n",
    "                     [df_notr_zor] * 50 + \n",
    "                     [df_poz_zor] * 50, ignore_index=True)\n",
    "\n",
    "\n",
    "# --- 4. VERÄ° ARTIRMA VE DENGELEME (GARANTÄ°LÄ° YÃ–NTEM) ---\n",
    "print(\"\\nGenel Veri ArtÄ±rma (Random Swap) BaÅŸlÄ±yor...\")\n",
    "\n",
    "def veri_artir_swap(metin):\n",
    "    kelimeler = metin.split()\n",
    "    if len(kelimeler) < 4: return metin\n",
    "    idx1, idx2 = random.sample(range(len(kelimeler)), 2)\n",
    "    kelimeler[idx1], kelimeler[idx2] = kelimeler[idx2], kelimeler[idx1]\n",
    "    return \" \".join(kelimeler)\n",
    "\n",
    "sinif_dagilimi = df_final['Etiket_Sayisal'].value_counts()\n",
    "hedef_sayi = sinif_dagilimi.max()\n",
    "\n",
    "tum_veriler = []\n",
    "for etiket in sinif_dagilimi.index:\n",
    "    df_sinif = df_final[df_final['Etiket_Sayisal'] == etiket].copy()\n",
    "    tum_veriler.append(df_sinif)\n",
    "    \n",
    "    mevcut_sayi = len(df_sinif)\n",
    "    if mevcut_sayi < hedef_sayi:\n",
    "        eksik = hedef_sayi - mevcut_sayi\n",
    "        kaynak = df_sinif['Temiz_Metin'].sample(n=eksik, replace=True, random_state=42).tolist()\n",
    "        yeni = [veri_artir_swap(m) for m in kaynak]\n",
    "        \n",
    "        df_yeni = pd.DataFrame({\n",
    "            'Metin': kaynak,\n",
    "            'Etiket_Sayisal': [etiket] * len(yeni),\n",
    "            'Temiz_Metin': yeni\n",
    "        })\n",
    "        tum_veriler.append(df_yeni)\n",
    "\n",
    "df_dengeli = pd.concat(tum_veriler, ignore_index=True)\n",
    "# KarÄ±ÅŸtÄ±r\n",
    "df_dengeli = df_dengeli.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# --- 5. EÄÄ°TÄ°M ---\n",
    "print(\"\\nModel eÄŸitiliyor...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_vec = vectorizer.fit_transform(df_dengeli['Temiz_Metin'])\n",
    "y = df_dengeli['Etiket_Sayisal']\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_vec, y)\n",
    "\n",
    "joblib.dump(model, 'final_model.pkl')\n",
    "joblib.dump(vectorizer, 'final_vectorizer.pkl')\n",
    "\n",
    "print(\"\\nğŸ‰ MÃœKEMMEL! Model artÄ±k her konuyu (Kitap, Film, AlÄ±ÅŸveriÅŸ) Ã§ok daha iyi anlÄ±yor.\")\n",
    "print(\"'app.py' uygulamasÄ±nÄ± yeniden baÅŸlatÄ±p deneyebilirsin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f514b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
